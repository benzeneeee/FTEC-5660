{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RRbStil_qkQc",
        "kCENjOq6owDd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2"
      ],
      "metadata": {
        "id": "tFaf7VErZ1Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "I3g3k3W-qfAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "6vsESFZylO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install 'markitdown[pdf]'\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ],
      "metadata": {
        "id": "Hrdfpmv9nMpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd4e072-b9cd-4f85-a366-97a31bc2a9ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: markitdown[pdf] in /usr/local/lib/python3.12/dist-packages (0.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
            "Requirement already satisfied: magika~=0.6.1 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.6.3)\n",
            "Requirement already satisfied: markdownify in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
            "Requirement already satisfied: pdfminer-six in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (20260107)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.24.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six->markitdown[pdf]) (43.0.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six->markitdown[pdf]) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six->markitdown[pdf]) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
            "Requirement already satisfied: langchain_mcp_adapters in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (4.2.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.10)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.13)\n",
            "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.20.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.1)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.40.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
        "\n",
        "\n",
        "1.   Look for the key icon on the left panel of your colab.\n",
        "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
        "3. Copy your key to `Value`.\n",
        "\n",
        "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
        "\n"
      ],
      "metadata": {
        "id": "BUav-7KdaY_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
        "# DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')"
      ],
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download sample CVs"
      ],
      "metadata": {
        "id": "RRbStil_qkQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading sample_cv.pdf\n",
        "The codes below download the sample CV\n"
      ],
      "metadata": {
        "id": "kCENjOq6owDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCCp8DwPF4L",
        "outputId": "051eacfa-9254-4508-80c5-e358e0aa6ef7",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
            "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
            "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
            "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
            "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
            "To: /content/downloaded_cvs/CV_1.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 69.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
            "To: /content/downloaded_cvs/CV_2.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 25.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
            "To: /content/downloaded_cvs/CV_3.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 68.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
            "To: /content/downloaded_cvs/CV_4.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 67.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
            "To: /content/downloaded_cvs/CV_5.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 40.3MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['downloaded_cvs/CV_1.pdf',\n",
              " 'downloaded_cvs/CV_2.pdf',\n",
              " 'downloaded_cvs/CV_3.pdf',\n",
              " 'downloaded_cvs/CV_4.pdf',\n",
              " 'downloaded_cvs/CV_5.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ðŸ“„ {pdf_name}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result.text_content)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2akmVn9LODIu",
        "outputId": "df7e83d7-4100-4cf2-b8d1-a35f98fb415a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ðŸ“„ CV_1.pdf\n",
            "================================================================================\n",
            "John Smith\n",
            "\n",
            "Marketing Professional\n",
            "\n",
            "+ Singapore, Singapore (cid:209) Kowloon\n",
            "\n",
            "Experience\n",
            "\n",
            "Engineer, ByteDance\n",
            "\n",
            "2020 â€“ Present\n",
            "\n",
            "â€¢ Worked in a fast-paced, global technology environment.\n",
            "\n",
            "â€¢ Collaborated across teams to support large-scale platforms.\n",
            "\n",
            "â€¢ Applied analytical and problem-solving skills in production systems.\n",
            "\n",
            "Education\n",
            "\n",
            "McGill University\n",
            "\n",
            "Bachelor of Science (BSc) in Marketing\n",
            "\n",
            "Skills\n",
            "\n",
            "Content Creation\n",
            "\n",
            "SEO\n",
            "\n",
            "Social Media\n",
            "\n",
            "Graduated 2009\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_2.pdf\n",
            "================================================================================\n",
            "Minh Pham\n",
            "Design Professional\n",
            "\n",
            "Beijing, China | Hong Kong\n",
            "\n",
            "Professional Experience\n",
            "\n",
            "Manager, BCG\n",
            "\n",
            "2022 â€“ Present\n",
            "\n",
            "â€¢ Led cross-functional teams on client-facing design initiatives.\n",
            "\n",
            "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
            "\n",
            "â€¢ Applied design thinking to business and strategy problems.\n",
            "\n",
            "Analyst, Tencent\n",
            "\n",
            "2013 â€“ 2017\n",
            "\n",
            "â€¢ Conducted market and product analysis to support decision-making.\n",
            "\n",
            "â€¢ Collaborated with design and engineering teams.\n",
            "\n",
            "â€¢ Produced reports and insights for senior leadership.\n",
            "\n",
            "Education\n",
            "\n",
            "BSc in Design\n",
            "The University of Hong Kong\n",
            "\n",
            "Skills\n",
            "\n",
            "â€¢ UI/UX Design\n",
            "\n",
            "â€¢ Prototyping\n",
            "\n",
            "â€¢ Graphic Design\n",
            "\n",
            "2011\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_3.pdf\n",
            "================================================================================\n",
            "Wei Zhang\n",
            "Consulting Professional\n",
            "\n",
            "Professional Experience\n",
            "\n",
            "2013 â€“ Present\n",
            "\n",
            "Engineer, PwC\n",
            "\n",
            "Munich, Germany\n",
            "Sydney (Hometown)\n",
            "\n",
            "â€¢ Supported consulting engagements across multiple client\n",
            "\n",
            "projects.\n",
            "\n",
            "â€¢ Performed data analysis to inform strategic recommen-\n",
            "\n",
            "dations.\n",
            "\n",
            "â€¢ Collaborated with cross-functional teams in a profes-\n",
            "\n",
            "sional services environment.\n",
            "\n",
            "Education\n",
            "\n",
            "2015\n",
            "\n",
            "Skills\n",
            "\n",
            "BSc in Consulting\n",
            "University of Tokyo\n",
            "\n",
            "Analytical\n",
            "Business\n",
            "\n",
            "Data Analysis, Problem Solving\n",
            "Strategy, PowerPoint\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_4.pdf\n",
            "================================================================================\n",
            "Rahul Sharma\n",
            "Legal Professional\n",
            "Singapore (Hometown) | Singapore / Philippines\n",
            "\n",
            "Professional Experience\n",
            "\n",
            "2021 â€“ 2027\n",
            "\n",
            "Senior Engineer, Microsoft\n",
            "\n",
            "â€¢ Led compliance-focused initiatives within large-scale techni-\n",
            "\n",
            "cal teams.\n",
            "\n",
            "â€¢ Advised on regulatory, legal, and risk considerations for com-\n",
            "\n",
            "plex systems.\n",
            "\n",
            "â€¢ Worked at the intersection of law, technology, and gover-\n",
            "\n",
            "nance.\n",
            "\n",
            "2020 â€“ 2023\n",
            "\n",
            "Consultant, StartupXYZ\n",
            "\n",
            "â€¢ Provided legal and strategic consulting for early-stage com-\n",
            "\n",
            "panies.\n",
            "\n",
            "â€¢ Supported contract review, compliance, and operational risk\n",
            "\n",
            "management.\n",
            "\n",
            "â€¢ Engaged with cross-functional and international stakehold-\n",
            "\n",
            "ers.\n",
            "\n",
            "Education\n",
            "\n",
            "2021\n",
            "\n",
            "Skills\n",
            "\n",
            "PhD in Legal Studies\n",
            "Tsinghua University\n",
            "\n",
            "Compliance, Litigation, Contract Review\n",
            "Web3, Machine Learning, Quantum Computing\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“„ CV_5.pdf\n",
            "================================================================================\n",
            "Rahul Sharma\n",
            "AI Professional\n",
            "London | Hong Kong | Singapore (Hometown)\n",
            "\n",
            "Core Skills\n",
            "\n",
            "Professional Experience\n",
            "\n",
            "Machine Learning & AI\n",
            "\n",
            "â€¢ Advanced AI Systems\n",
            "\n",
            "â€¢ Machine Learning (ML)\n",
            "\n",
            "Senior Engineer\n",
            "EY\n",
            "\n",
            "Current\n",
            "\n",
            "â€¢ Designed and evaluated AI-driven solutions for\n",
            "\n",
            "enterprise clients.\n",
            "\n",
            "â€¢ Applied ML techniques to large-scale business\n",
            "\n",
            "â€¢ Natural Language Processing (NLP)\n",
            "\n",
            "Frameworks & Tools\n",
            "\n",
            "problems.\n",
            "\n",
            "Consultant\n",
            "StartupXYZ\n",
            "\n",
            "2019 â€“ 2021\n",
            "\n",
            "â€¢ TensorFlow\n",
            "\n",
            "â€¢ PyTorch\n",
            "\n",
            "â€¢ Python\n",
            "\n",
            "Education\n",
            "\n",
            "â€¢ Provided AI and data strategy advisory to\n",
            "\n",
            "early-stage companies.\n",
            "\n",
            "Senior Analyst\n",
            "DataForge\n",
            "\n",
            "2016 â€“ Present\n",
            "\n",
            "â€¢ Conducted advanced data analysis and model\n",
            "\n",
            "evaluation.\n",
            "\n",
            "Lead Scientist\n",
            "UrbanFlow\n",
            "\n",
            "2010 â€“ 2017\n",
            "\n",
            "PhD in Artificial Intelligence\n",
            "University of Tokyo\n",
            "2012\n",
            "\n",
            "â€¢ Led research initiatives in applied AI systems.\n",
            "\n",
            "â€¢ Mentored junior researchers and engineers.\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to our MCP server\n",
        "\n",
        "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
        "\n",
        "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
      ],
      "metadata": {
        "id": "VA2GvPWTQFt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check which tools that the MCP server provide"
      ],
      "metadata": {
        "id": "5mbkH9xHXfmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "for tool in mcp_tools:\n",
        "    print(tool.name)\n",
        "    print(tool.description)\n",
        "    print(tool.args)\n",
        "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h0311KbN9A3",
        "outputId": "b8a52460-c458-4e09-cd06-8681d9a24446"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search_facebook_users\n",
            "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
            "\n",
            "Args:\n",
            "    q: Search query string (case-insensitive, matches any part of display name)\n",
            "       Examples: \"John\", \"john smith\", \"Smith\"\n",
            "    limit: Maximum number of results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of user dictionaries, each containing:\n",
            "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
            "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
            "    - city (str): Current city of residence\n",
            "    - country (str): Country of residence\n",
            "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_facebook_users(\"Alex Chan\", limit=5)\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
            "    personal information, location, and social connections. Handles typos and variations.\n",
            "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_profile\n",
            "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
            "\n",
            "Args:\n",
            "    user_id: Facebook user ID obtained from search_facebook_users()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): Facebook user ID\n",
            "    - display_name (str): Public display name (may be nickname)\n",
            "    - original_name (str): Original/legal name from LinkedIn\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - hometown (str|None): City/region where user grew up\n",
            "    - bio (str): Personal biography/interests\n",
            "    - status (str|None): Relationship status (Single, Married, etc.)\n",
            "    - education (str|None): Highest education level\n",
            "    - current_job (str|None): Current job title\n",
            "    - current_company (str|None): Current employer\n",
            "    - interests (str): Comma-separated hobbies/interests\n",
            "    - friends (List[int]): List of friend user IDs\n",
            "    - posts (List[dict]): Recent posts with id and content\n",
            "    \n",
            "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_facebook_profile(123)\n",
            "    â†’ {\n",
            "        \"id\": 123,\n",
            "        \"display_name\": \"Sam Chan\",\n",
            "        \"original_name\": \"Alex Chan\",\n",
            "        \"city\": \"Hong Kong\",\n",
            "        \"hometown\": \"Kowloon\",\n",
            "        \"bio\": \"Software professional | Photography enthusiast\",\n",
            "        \"status\": \"Married\",\n",
            "        \"current_job\": \"Senior Engineer\",\n",
            "        \"current_company\": \"Google\",\n",
            "        \"friends\": [124, 125, 126],\n",
            "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Verify candidate's personal details, check for name discrepancies,\n",
            "    validate current employment, and assess social connections.\n",
            "{'user_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_mutual_friends\n",
            "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
            "\n",
            "Args:\n",
            "    user_id_1: First Facebook user ID\n",
            "    user_id_2: Second Facebook user ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - user_1_id (int): First user's ID\n",
            "    - user_2_id (int): Second user's ID\n",
            "    - mutual_friends (List[int]): List of shared friend IDs\n",
            "    - mutual_count (int): Number of mutual friends\n",
            "    \n",
            "    Returns {\"error\": \"...\"} if either user not found.\n",
            "\n",
            "Example:\n",
            "    get_facebook_mutual_friends(123, 456)\n",
            "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
            "\n",
            "Use case:\n",
            "    Verify professional or personal relationships claimed in CV/references.\n",
            "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "search_linkedin_people\n",
            "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
            "\n",
            "Args:\n",
            "    q: Search query (matches name, headline, summary, or skill names)\n",
            "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
            "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
            "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
            "    industry: Filter by industry (optional, case-insensitive)\n",
            "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
            "    limit: Maximum results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of profile dictionaries, each containing:\n",
            "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline/title\n",
            "    - industry (str): Industry sector\n",
            "    - location (str): \"City, Country\" format\n",
            "    - years_experience (int): Total years of work experience\n",
            "    - match_type (str): \"exact\" or \"fuzzy\"\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
            "    Use location filter to narrow down results when common names exist. Handles typos.\n",
            "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_profile\n",
            "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): LinkedIn profile ID\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - industry (str): Primary industry\n",
            "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
            "    - years_experience (int): Total years of professional experience\n",
            "    - summary (str): Professional summary/bio\n",
            "    \n",
            "    - skills (List[dict]): Each containing:\n",
            "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
            "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
            "    \n",
            "    - experience (List[dict]): Work history, each containing:\n",
            "        * company (str): Employer name\n",
            "        * title (str): Job title\n",
            "        * seniority (str): Level (junior, mid, senior)\n",
            "        * start_year (int): Employment start year\n",
            "        * end_year (int|None): Employment end year (None if current)\n",
            "        * is_current (bool): Whether currently employed here\n",
            "    \n",
            "    - education (List[dict]): Academic history, each containing:\n",
            "        * school (str): Institution name\n",
            "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
            "        * field (str): Field of study\n",
            "        * start_year (int): Start year\n",
            "        * end_year (int): Graduation year\n",
            "    \n",
            "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_profile(456)\n",
            "    â†’ {\n",
            "        \"id\": 456,\n",
            "        \"name\": \"Alex Chan\",\n",
            "        \"headline\": \"Senior Software Engineer\",\n",
            "        \"years_experience\": 8,\n",
            "        \"skills\": [\n",
            "            {\"name\": \"Python\", \"proficiency\": 5},\n",
            "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
            "        ],\n",
            "        \"experience\": [\n",
            "            {\n",
            "                \"company\": \"Google\",\n",
            "                \"title\": \"Senior Engineer\",\n",
            "                \"seniority\": \"senior\",\n",
            "                \"start_year\": 2020,\n",
            "                \"end_year\": None,\n",
            "                \"is_current\": True\n",
            "            }\n",
            "        ],\n",
            "        \"education\": [\n",
            "            {\n",
            "                \"school\": \"HKUST\",\n",
            "                \"degree\": \"BSc\",\n",
            "                \"field\": \"Computer Science\",\n",
            "                \"start_year\": 2010,\n",
            "                \"end_year\": 2014\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Primary tool for CV verification - compare claimed experience, education,\n",
            "    skills, and employment dates against LinkedIn ground truth.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_interactions\n",
            "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - profile_id (int): The person's LinkedIn ID\n",
            "    - post_count (int): Number of posts made\n",
            "    - total_likes (int): Total likes received across all posts\n",
            "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
            "    - engagement_score (float): Likes per post ratio\n",
            "    \n",
            "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_interactions(456)\n",
            "    â†’ {\n",
            "        \"profile_id\": 456,\n",
            "        \"post_count\": 10,\n",
            "        \"total_likes\": 150,\n",
            "        \"liked_by\": [123, 124, 125],\n",
            "        \"engagement_score\": 15.0\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Assess professional network strength and content engagement.\n",
            "    Verify connections to claimed colleagues or industry peers.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A simple agent using tools from the MCP server\n"
      ],
      "metadata": {
        "id": "ABoe2-qfXl7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# ---------------------------\n",
        "# 1. èŽ·å– API Key å¹¶åˆå§‹åŒ–ä½ æŒ‡å®šçš„ LLM\n",
        "# ---------------------------\n",
        "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
        "\n",
        "# ä½¿ç”¨ä½ æä¾›çš„ init_chat_model é…ç½®\n",
        "llm = init_chat_model(\n",
        "    \"gemini-2.5-flash\",\n",
        "    api_key=GEMINI_VERTEX_API_KEY,\n",
        "    model_provider=\"openai\",\n",
        "    base_url=\"https://aihubmix.com/v1\",\n",
        "    temperature=0,  # å¯¹äºŽ Agent ä»»åŠ¡ï¼Œå»ºè®®å°† temperature è®¾ä¸º 0 ä»¥ä¿è¯è¾“å‡ºç¨³å®šæ€§\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 2. å®šä¹‰æœ¬åœ°å·¥å…· (Local Tool)\n",
        "# ---------------------------\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to a person by name.\"\"\"\n",
        "    return f\"Hello, {name}! ðŸ‘‹\"\n",
        "\n",
        "# ---------------------------\n",
        "# 3. åŠ è½½ MCP æœåŠ¡å™¨å·¥å…·å¹¶åˆå¹¶\n",
        "# ---------------------------\n",
        "# è¿™é‡Œè¿žæŽ¥çš„æ˜¯ä½œä¸šè¦æ±‚çš„ SocialGraph MCP æœåŠ¡å™¨ [cite: 6, 33]\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "# å¼‚æ­¥èŽ·å– MCP æä¾›çš„ç¤¾äº¤åª’ä½“éªŒè¯å·¥å…·ï¼ˆå¦‚ search_facebook_users ç­‰ï¼‰ [cite: 35, 109]\n",
        "mcp_tools = await client.get_tools()\n",
        "tools = mcp_tools + [say_hello]\n",
        "\n",
        "# å°†å·¥å…·ç»‘å®šåˆ°ä½ çš„ Gemini æ¨¡åž‹ä¸Š\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. æ‰§è¡Œå•æ­¥è°ƒç”¨ (Single-step invocation)\n",
        "# ---------------------------\n",
        "# Agent ä¼šæ ¹æ® query è‡ªåŠ¨å†³å®šè°ƒç”¨ say_hello è¿˜æ˜¯ MCP çš„æœç´¢å·¥å…· [cite: 21, 27]\n",
        "query = \"Say hello to Bao using tool, then search for someone named Rahul Sharma on Facebook.\"\n",
        "\n",
        "response = llm_with_tools.invoke([\n",
        "    HumanMessage(content=query)\n",
        "])\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtTjwFKhTKn3",
        "outputId": "98728d4d-f5ff-4be4-db3a-f239546d6fd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 2569, 'total_tokens': 2694, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 111, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0, 'image_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gemini-2.5-flash', 'system_fingerprint': None, 'id': 'chatcmpl-da432c78f0b74a14b9fd19f6853a75a3', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019c7170-c7e7-7ce1-bd18-f04ae66b58a3-0' tool_calls=[{'name': 'say_hello', 'args': {'name': 'Bao'}, 'id': 'call_d3ca63f657c84ea39556f7842a71bbc4', 'type': 'tool_call'}, {'name': 'search_facebook_users', 'args': {'q': 'Rahul Sharma'}, 'id': 'call_9853c344cc864b9791deed2c3fca53bc', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 2569, 'output_tokens': 125, 'total_tokens': 2694, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 111}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This block provides you some tests to get faminilar with our MCP server\n",
        "\n",
        "# # Test 1: Search Facebook users (exact match)\n",
        "# await tools[0].ainvoke({'q': \"Alex Chan\", 'limit': 5})\n",
        "\n",
        "# # Test 2: Search Facebook users (fuzzy match with typo)\n",
        "# await tools[0].ainvoke({'q': \"Alx Chn\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 3: Get Facebook profile\n",
        "# await tools[1].ainvoke({'user_id': 123})\n",
        "\n",
        "# # Test 4: Get Facebook mutual friends\n",
        "# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
        "\n",
        "# # Test 5: Search LinkedIn people (exact match)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
        "\n",
        "# # Test 6: Search LinkedIn people (fuzzy match with typo)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 7: Get LinkedIn profile\n",
        "# await tools[4].ainvoke({'person_id': 456})\n",
        "\n",
        "# Test 8: Get LinkedIn interactions\n",
        "await tools[5].ainvoke({'person_id': 456})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLeoXGrqesW",
        "outputId": "881ea971-fd67-44ba-b238-e368a179ea08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'text',\n",
              "  'text': '{\"profile_id\":456,\"post_count\":4,\"total_likes\":5,\"liked_by\":[4390,3622,7500,4269,8464],\"engagement_score\":1.25}',\n",
              "  'id': 'lc_6e1dbbdd-25df-4691-afcc-ce360028775c'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CV Verification System\n",
        "####Import"
      ],
      "metadata": {
        "id": "zdg6CVo72uBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "import asyncio\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "from google.colab import userdata\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# -------------------------\n",
        "# 1. ç³»ç»Ÿç‰ˆæœ¬ä¸Žç­–ç•¥å¸¸é‡é…ç½® (ä¿æŒåŽŸç‰ˆé€»è¾‘) [cite: 18, 22]\n",
        "# -------------------------\n",
        "PIPELINE_VERSION = \"2026-02-18-gemini-logic-v5.2\"\n",
        "\n",
        "PASS_THRESHOLD = 0.50          # åˆ¤å®šåŠæ ¼çš„åˆ†æ•°çº¿ [cite: 263]\n",
        "MAX_CV_VERIFY_CONCURRENCY = 2  # å¹¶å‘å¤„ç†ç®€åŽ†çš„æ•°é‡é™åˆ¶\n",
        "TOOL_TIMEOUT_S = 10.0          # MCP å·¥å…·è°ƒç”¨è¶…æ—¶æ—¶é—´\n",
        "MAX_TOOL_RETRIES = 1           # å¤±è´¥é‡è¯•æ¬¡æ•°\n",
        "\n",
        "# åŒ¹é…ç®—æ³•ç›¸å…³é˜ˆå€¼ [cite: 265]\n",
        "MAX_CANDIDATES_PER_SOURCE = 3\n",
        "MAX_PROFILES_PER_SOURCE = 2\n",
        "HARD_FAIL_NAME_SIM_THRESHOLD = 0.35\n",
        "HARD_FAIL_NO_PROFILE_SCORE = 0.0\n",
        "HARD_FAIL_NETWORK_SCORE = 0.0\n",
        "HARD_FAIL_FUTURE_DATE_SCORE = 0.20\n",
        "\n",
        "ENABLE_LOGS = True\n",
        "\n",
        "# å‡†å¤‡ç®€åŽ†æ–‡ä»¶åˆ—è¡¨ [cite: 6]\n",
        "cv_files = [f\"downloaded_cvs/CV_{i}.pdf\" for i in range(1, 6)]\n",
        "\n",
        "# å±è”½ä¸å¿…è¦çš„ç½‘ç»œåº“æ—¥å¿—ï¼Œä¿æŒè¾“å‡ºæ•´æ´\n",
        "logging.getLogger(\"mcp.client.streamable_http\").setLevel(logging.CRITICAL)\n",
        "logging.getLogger(\"httpx\").setLevel(logging.ERROR)\n",
        "\n",
        "# -------------------------\n",
        "# 2. è¿žæŽ¥ MCP æœåŠ¡å™¨å¹¶åŠ è½½ç¤¾äº¤å·¥å…· [cite: 6, 33]\n",
        "# -------------------------\n",
        "client = MultiServerMCPClient(\n",
        "    {\n",
        "        \"social_graph\": {\n",
        "            \"transport\": \"http\",\n",
        "            \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "            \"headers\": {\"ngrok-skip-browser-warning\": \"true\"},\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "# å¼‚æ­¥èŽ·å–æ‰€æœ‰ MCP å·¥å…·\n",
        "mcp_tools = await client.get_tools()\n",
        "tool_by_name = {t.name: t for t in mcp_tools}\n",
        "\n",
        "# éªŒè¯ä½œä¸šè¦æ±‚çš„ 6 ä¸ªæ ¸å¿ƒå·¥å…·æ˜¯å¦å…¨éƒ¨åŠ è½½æˆåŠŸ [cite: 35, 65, 93, 109, 145, 191]\n",
        "_REQUIRED_TOOLS = [\n",
        "    \"search_facebook_users\",      # [cite: 35]\n",
        "    \"get_facebook_profile\",       # [cite: 65]\n",
        "    \"get_facebook_mutual_friends\",# [cite: 93]\n",
        "    \"search_linkedin_people\",     # [cite: 109]\n",
        "    \"get_linkedin_profile\",      #\n",
        "    \"get_linkedin_interactions\",  # [cite: 191]\n",
        "]\n",
        "\n",
        "missing = [n for n in _REQUIRED_TOOLS if n not in tool_by_name]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"å…³é”® MCP å·¥å…·ç¼ºå¤±: {missing}\")\n",
        "\n",
        "# æ˜ å°„å·¥å…·å˜é‡ä»¥ä¾¿åŽç»­ç›´æŽ¥è°ƒç”¨\n",
        "search_facebook_users = tool_by_name[\"search_facebook_users\"]\n",
        "get_facebook_profile = tool_by_name[\"get_facebook_profile\"]\n",
        "get_facebook_mutual_friends = tool_by_name[\"get_facebook_mutual_friends\"]\n",
        "search_linkedin_people = tool_by_name[\"search_linkedin_people\"]\n",
        "get_linkedin_profile = tool_by_name[\"get_linkedin_profile\"]\n",
        "get_linkedin_interactions = tool_by_name[\"get_linkedin_interactions\"]\n",
        "\n",
        "# -------------------------\n",
        "# 3. ä½¿ç”¨ä½ çš„ Gemini 2.5 é…ç½®åˆå§‹åŒ– LLM\n",
        "# -------------------------\n",
        "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
        "\n",
        "llm = init_chat_model(\n",
        "    \"gemini-2.5-flash\",\n",
        "    api_key=GEMINI_VERTEX_API_KEY,\n",
        "    model_provider=\"openai\",\n",
        "    base_url=\"https://aihubmix.com/v1\",\n",
        "    temperature=0,  # éªŒè¯ä»»åŠ¡éœ€è¦æžå…¶ä¸¥è°¨ï¼Œå¿…é¡»è®¾ä¸º 0 [cite: 21]\n",
        ")\n",
        "\n",
        "# æ‰“å°åˆå§‹åŒ–æˆåŠŸçŠ¶æ€\n",
        "print(json.dumps({\"event\": \"pipeline.version\", \"version\": PIPELINE_VERSION}, ensure_ascii=False))\n",
        "print(json.dumps({\"event\": \"mcp.tools.ready\", \"count\": len(_REQUIRED_TOOLS)}, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9KPrhij2QJR",
        "outputId": "57dced24-3394-4b69-bcfa-2f6bb26f936a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"event\": \"pipeline.version\", \"version\": \"2026-02-18-gemini-logic-v5.2\"}\n",
            "{\"event\": \"mcp.tools.ready\", \"count\": 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####registration"
      ],
      "metadata": {
        "id": "XyKyaZ9S4rmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import asyncio\n",
        "import logging\n",
        "from difflib import SequenceMatcher\n",
        "from pathlib import Path\n",
        "\n",
        "# -------------------------\n",
        "# 1. åŸºç¡€å·¥å…·å‡½æ•°ï¼šæ—¥å¿—ä¸Žæ•°æ®æ¸…æ´—\n",
        "# -------------------------\n",
        "def _log_event(event: str, **payload):\n",
        "    \"\"\"ç»Ÿä¸€çš„ JSON æ ¼å¼æ—¥å¿—è¾“å‡ºï¼Œä¾¿äºŽè°ƒè¯•ä¸Žç›‘æŽ§ã€‚\"\"\"\n",
        "    if not ENABLE_LOGS:\n",
        "        return\n",
        "    rec = {\"event\": event}\n",
        "    rec.update(payload)\n",
        "    print(json.dumps(rec, ensure_ascii=False))\n",
        "\n",
        "def _safe_list(x):\n",
        "    \"\"\"ç¡®ä¿è¾“å…¥å§‹ç»ˆä¸ºåˆ—è¡¨æ ¼å¼ï¼Œé˜²æ­¢ç±»åž‹é”™è¯¯ã€‚\"\"\"\n",
        "    return x if isinstance(x, list) else []\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    \"\"\"æ ‡å‡†åŒ–å­—ç¬¦ä¸²ï¼šè½¬ä¸ºå°å†™å¹¶ç§»é™¤éžå­—æ¯æ•°å­—å­—ç¬¦ [cite: 36, 110]ã€‚\"\"\"\n",
        "    return re.sub(r\"[^a-z0-9]+\", \" \", str(s or \"\").lower()).strip()\n",
        "\n",
        "def _sim(a: str, b: str) -> float:\n",
        "    \"\"\"è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ï¼ˆ0.0 - 1.0ï¼‰ï¼Œç”¨äºŽå¤„ç†åå­—æ‹¼å†™å·®å¼‚ [cite: 36, 119]ã€‚\"\"\"\n",
        "    a_n, b_n = _norm(a), _norm(b)\n",
        "    if not a_n or not b_n:\n",
        "        return 0.0\n",
        "    return SequenceMatcher(None, a_n, b_n).ratio()\n",
        "\n",
        "def _tokenize(text: str):\n",
        "    \"\"\"å°†æ–‡æœ¬åˆ‡åˆ†ä¸ºé•¿åº¦è‡³å°‘ä¸º 3 çš„å…³é”®è¯ï¼Œç”¨äºŽé‡å åº¦æ ¡éªŒã€‚\"\"\"\n",
        "    return [t for t in _norm(text).split() if len(t) >= 3]\n",
        "\n",
        "# -------------------------\n",
        "# 2. å·¥å…·è°ƒç”¨å¢žå¼ºï¼šå®¹é”™ä¸Žç¼“å­˜\n",
        "# -------------------------\n",
        "_NAME_SEARCH_CACHE = globals().get(\"_NAME_SEARCH_CACHE\", {})\n",
        "_PROFILE_CACHE = globals().get(\"_PROFILE_CACHE\", {})\n",
        "_NAME_LOCKS = globals().get(\"_NAME_LOCKS\", {})\n",
        "\n",
        "def _get_name_lock(name: str):\n",
        "    \"\"\"ä¸ºç‰¹å®šå€™é€‰äººå§“ååˆ›å»ºå¼‚æ­¥é”ï¼Œé˜²æ­¢å¹¶å‘å†²çªã€‚\"\"\"\n",
        "    key = _norm(name or \"\") or \"__empty__\"\n",
        "    lock = _NAME_LOCKS.get(key)\n",
        "    if lock is None:\n",
        "        lock = asyncio.Lock()\n",
        "        _NAME_LOCKS[key] = lock\n",
        "    return lock\n",
        "\n",
        "def _unwrap_tool_result(res):\n",
        "    \"\"\"è§£æžå·¥å…·è¿”å›žçš„åŽŸå§‹å“åº”ï¼Œæå– JSON æ–‡æœ¬å†…å®¹ã€‚\"\"\"\n",
        "    if isinstance(res, list) and len(res) == 1 and isinstance(res[0], dict) and \"text\" in res[0]:\n",
        "        txt = str(res[0].get(\"text\", \"\") or \"\")\n",
        "        try:\n",
        "            return json.loads(txt)\n",
        "        except Exception:\n",
        "            return txt\n",
        "    return res\n",
        "\n",
        "def _is_network_error(err_text: str) -> bool:\n",
        "    \"\"\"è¯†åˆ«å¸¸è§çš„ç½‘ç»œæ³¢åŠ¨å…³é”®è¯ï¼Œç”¨äºŽè§¦å‘é‡è¯•é€»è¾‘ã€‚\"\"\"\n",
        "    t = str(err_text or \"\").lower()\n",
        "    keys = [\"timeout\", \"connectionerror\", \"connecterror\", \"streamable_http\", \"tls\", \"broken pipe\"]\n",
        "    return any(k in t for k in keys)\n",
        "\n",
        "async def _call_tool(tool, payload: dict, label: str, timeout_s: float = TOOL_TIMEOUT_S, retries: int = MAX_TOOL_RETRIES):\n",
        "    \"\"\"\n",
        "    å¸¦æœ‰é‡è¯•æœºåˆ¶å’Œè¶…æ—¶ä¿æŠ¤çš„å·¥å…·è°ƒç”¨å‡½æ•° [cite: 24]ã€‚\n",
        "    \"\"\"\n",
        "    last_err = None\n",
        "    for i in range(int(retries) + 1):\n",
        "        try:\n",
        "            # å¼‚æ­¥æ‰§è¡Œå·¥å…·å¹¶è®¾ç½®è¶…æ—¶é™åˆ¶\n",
        "            raw = await asyncio.wait_for(tool.ainvoke(payload), timeout=timeout_s)\n",
        "            return _unwrap_tool_result(raw), None\n",
        "        except Exception as e:\n",
        "            last_err = f\"{label}: {type(e).__name__}: {e}\"\n",
        "            # å¦‚æžœæ˜¯ç½‘ç»œé”™è¯¯åˆ™æŒ‡æ•°å›žé€€å¹¶é‡è¯•\n",
        "            if i < int(retries) and _is_network_error(last_err):\n",
        "                await asyncio.sleep(0.35 * (i + 1))\n",
        "                continue\n",
        "            break\n",
        "    return None, last_err\n",
        "\n",
        "# -------------------------\n",
        "# 3. ç®€åŽ†è§£æžé€»è¾‘ (CV Parsing)\n",
        "# -------------------------\n",
        "def extract_text_pdf(path: str) -> str:\n",
        "    \"\"\"ä»Ž PDF æ–‡ä»¶ä¸­æå–æ–‡æœ¬ ã€‚\"\"\"\n",
        "    try:\n",
        "        from markitdown import MarkItDown\n",
        "        return MarkItDown().convert(path).text_content\n",
        "    except Exception:\n",
        "        from PyPDF2 import PdfReader\n",
        "        r = PdfReader(path)\n",
        "        return \"\\n\".join(page.extract_text() or \"\" for page in r.pages)\n",
        "\n",
        "def parse_cv(text: str) -> dict:\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨å¯å‘å¼ç®—æ³•å’Œæ­£åˆ™æå–ç®€åŽ†æ ¸å¿ƒå­—æ®µ ã€‚\n",
        "    \"\"\"\n",
        "    lines = [ln.strip() for ln in str(text or \"\").splitlines() if ln.strip()]\n",
        "\n",
        "    # æå–å§“åï¼ˆé€šå¸¸å‡ºçŽ°åœ¨å‰ 12 è¡Œä¸”éžé‚®ç®±/æ•°å­—ï¼‰\n",
        "    name = \"\"\n",
        "    for ln in lines[:12]:\n",
        "        if re.search(r\"@|\\d\", ln): continue\n",
        "        if 2 <= len(ln.split()) <= 4 and len(ln) <= 48:\n",
        "            name = ln\n",
        "            break\n",
        "\n",
        "    # æå–é‚®ç®±ä¸Žæ—¥æœŸ\n",
        "    emails = re.findall(r\"[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\", text or \"\", re.I)\n",
        "    email = emails[0] if emails else None\n",
        "\n",
        "    exp, edu, skills, years = [], [], [], []\n",
        "    for ln in lines:\n",
        "        # åŒ¹é…å¹´ä»½ç”¨äºŽåŽç»­çš„æ—¶é—´çº¿éªŒè¯ [cite: 28, 256]\n",
        "        if re.search(r\"(19|20)\\d{2}\", ln):\n",
        "            exp.append({\"raw\": ln})\n",
        "            years.extend([int(y) for y in re.findall(r\"(19\\d{2}|20\\d{2})\", ln)])\n",
        "        # åŒ¹é…æ•™è‚²å…³é”®è¯ [cite: 261]\n",
        "        if re.search(r\"University|College|Bachelor|Master|PhD|MSc|BSc\", ln, re.I):\n",
        "            edu.append({\"raw\": ln})\n",
        "        # åŒ¹é…æŠ€èƒ½å…³é”®è¯ [cite: 164]\n",
        "        if re.search(r\"skills?\", ln, re.I):\n",
        "            skills.extend([x.strip() for x in re.split(r\",|;|/|\\|\", ln) if x.strip()])\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"email\": email,\n",
        "        \"experience\": exp[:8],\n",
        "        \"education\": edu[:6],\n",
        "        \"skills\": skills[:25],\n",
        "        \"years\": years,\n",
        "        \"raw_text\": text,\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# 4. æ•°æ®æ ¼å¼åŒ–åŠ©æ‰‹\n",
        "# -------------------------\n",
        "def _candidate_name(row: dict) -> str:\n",
        "    \"\"\"ä»Žä¸åŒå¹³å°çš„å“åº”ä¸­æå–å€™é€‰äººåå­— [cite: 54, 125]ã€‚\"\"\"\n",
        "    if not isinstance(row, dict): return \"\"\n",
        "    return str(row.get(\"name\") or row.get(\"display_name\") or row.get(\"original_name\") or \"\")\n",
        "\n",
        "def _compact_profile(profile: dict) -> dict:\n",
        "    \"\"\"å°†å†—é•¿çš„ç¤¾äº¤ profile åŽ‹ç¼©ä¸ºå…³é”®ä¿¡æ¯ï¼Œå‡å°‘ LLM çš„ä¸Šä¸‹æ–‡æ¶ˆè€—ã€‚\"\"\"\n",
        "    if not isinstance(profile, dict): return {}\n",
        "    return {\n",
        "        \"name\": _candidate_name(profile),\n",
        "        \"location\": profile.get(\"location\") or \", \".join([x for x in [profile.get(\"city\"), profile.get(\"country\")] if x]),\n",
        "        \"headline\": profile.get(\"headline\") or profile.get(\"bio\") or profile.get(\"summary\")[cite: 126, 163],\n",
        "        \"experience\": _safe_list(profile.get(\"experience\", []))[:4],\n",
        "        \"education\": _safe_list(profile.get(\"education\", []))[:3],\n",
        "    }"
      ],
      "metadata": {
        "id": "pObU38UF4JJT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Judge Process"
      ],
      "metadata": {
        "id": "-NQoLEpCT6rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from textwrap import fill\n",
        "\n",
        "# 1. ç¡¬æ€§æ¼æ´žæ£€æµ‹é€»è¾‘\n",
        "def _build_hard_findings(cv_claim: dict, profiles: list, errors: list):\n",
        "    findings = []\n",
        "    if not profiles:\n",
        "        findings.append({\"severity\": \"critical\", \"code\": \"no_verifiable_profile\", \"evidence\": \"No profile fetched from MCP tools.\"})\n",
        "        if _network_error_count(errors) > 0:\n",
        "            findings.append({\"severity\": \"critical\", \"code\": \"network_unavailable\", \"evidence\": \"Search failed due to network errors.\"})\n",
        "        return findings\n",
        "\n",
        "    # æ£€æŸ¥å§“ååŒ¹é…åº¦\n",
        "    cv_name = cv_claim.get(\"name\") or \"\"\n",
        "    sims = [_sim(cv_name, _candidate_name(p.get(\"profile\", {}))) for p in _safe_list(profiles)]\n",
        "    best_sim = max(sims) if sims else 0.0\n",
        "    if best_sim < HARD_FAIL_NAME_SIM_THRESHOLD:\n",
        "        findings.append({\"severity\": \"critical\", \"code\": \"extreme_name_mismatch\", \"evidence\": f\"Best profile name similarity too low ({best_sim:.2f}).\"})\n",
        "\n",
        "    # æ£€æŸ¥æœªæ¥æ—¥æœŸ\n",
        "    current_year = datetime.now().year\n",
        "    future_years = [y for y in _safe_list(cv_claim.get(\"years\", [])) if y >= current_year + 1]\n",
        "    if future_years:\n",
        "        findings.append({\"severity\": \"high\", \"code\": \"future_date_claim\", \"evidence\": f\"CV includes far-future years: {sorted(list(set(future_years)))[:5]}\"})\n",
        "    return findings\n",
        "\n",
        "# 2. è‡ªåŠ¨åˆ¤å®šå†³ç­–é€»è¾‘\n",
        "def _hard_fail_decision(cv_claim: dict, profiles: list, findings: list):\n",
        "    if not profiles:\n",
        "        return True, HARD_FAIL_NO_PROFILE_SCORE, \"No verifiable external profile evidence\"\n",
        "\n",
        "    # å¦‚æžœå‘çŽ°æœªæ¥æ—¥æœŸæˆ–å§“åæžåº¦ä¸åŒ¹é…ï¼Œç›´æŽ¥åˆ¤å®šä¸ºå¤±è´¥\n",
        "    codes = [f.get(\"code\") for f in _safe_list(findings) if isinstance(f, dict)]\n",
        "    if \"extreme_name_mismatch\" in codes:\n",
        "        return True, HARD_FAIL_NETWORK_SCORE, \"Extreme name mismatch across fetched profiles\"\n",
        "    if \"future_date_claim\" in codes:\n",
        "        return True, HARD_FAIL_FUTURE_DATE_SCORE, \"Implausible future-dated CV timeline\"\n",
        "    return False, None, \"\"\n",
        "\n",
        "# 3. è¯æ®æ‰“åŒ…é€»è¾‘ (å‘ç»™ LLM çš„è¾“å…¥)\n",
        "def _build_evidence_pack(cv_id: str, cv_claim: dict, profiles: list, findings: list, errors: list):\n",
        "    profile_comparisons = [_profile_claim_overlap(cv_claim, p) for p in _safe_list(profiles)]\n",
        "    return {\n",
        "        \"cv_id\": cv_id,\n",
        "        \"cv_claim\": {\n",
        "            \"name\": cv_claim.get(\"name\"),\n",
        "            \"experience\": _safe_list(cv_claim.get(\"experience\", []))[:6],\n",
        "            \"education\": _safe_list(cv_claim.get(\"education\", []))[:6],\n",
        "        },\n",
        "        \"profile_comparisons\": profile_comparisons,\n",
        "        \"hard_findings\": findings[:8],\n",
        "    }\n",
        "\n",
        "# 4. æŠ¥å‘Šç”Ÿæˆæ–‡æœ¬æ¨¡æ¿\n",
        "def _build_report(cv_id, cv_claim, score, decision, confidence, rationale, findings, raw_score, profiles_count, tool_calls, errors):\n",
        "    rat_block = fill(str(rationale), width=88, initial_indent=\"  \", subsequent_indent=\"  \")\n",
        "    lines = [\n",
        "        f\"CV Verification Report | {cv_id}\",\n",
        "        \"-\" * 72,\n",
        "        \"Summary\",\n",
        "        f\"  Decision : {decision.upper()}\",\n",
        "        f\"  Score    : {score:.3f} (threshold={PASS_THRESHOLD:.2f})\",\n",
        "        f\"  Name     : {cv_claim.get('name')}\",\n",
        "        \"\",\n",
        "        \"Model Signals\",\n",
        "        f\"  LLM confidence : {confidence}\",\n",
        "        f\"  LLM score raw  : {float(raw_score):.3f}\",\n",
        "        \"\",\n",
        "        \"Search Evidence\",\n",
        "        f\"  Profiles fetched : {int(profiles_count)}\",\n",
        "        f\"  MCP tool calls   : {int(tool_calls)}\",\n",
        "        \"\",\n",
        "        \"Rationale\",\n",
        "        rat_block,\n",
        "        \"\",\n",
        "        \"Findings\",\n",
        "    ]\n",
        "    for f in findings:\n",
        "        msg = f.get('evidence', f) if isinstance(f, dict) else f\n",
        "        lines.append(f\"  - {msg}\")\n",
        "    return \"\\n\".join(lines)"
      ],
      "metadata": {
        "id": "KQyrTuuedSiJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "MAX_CV_VERIFY_CONCURRENCY = 1  # âš ï¸ å…³é”®ä¿®æ”¹ï¼šå¼ºåˆ¶å•çº¿ç¨‹æŽ’é˜Ÿï¼Œé˜²æ­¢è§¦å‘ç¬¬ä¸‰æ–¹ API é™æµ\n",
        "\n",
        "# -------------------------\n",
        "# 1. å€™é€‰äººæœç´¢é€»è¾‘ (Search Layer)\n",
        "# -------------------------\n",
        "async def _search_candidates(cv_name: str):\n",
        "    base = str(cv_name or \"\").strip()\n",
        "    if not base:\n",
        "        return [], [], [\"empty_name\"], 0\n",
        "\n",
        "    name_key = _norm(base)\n",
        "    queries = [base]\n",
        "    tokens = [t for t in name_key.split() if t]\n",
        "    if len(tokens) >= 2:\n",
        "        alt = f\"{tokens[0]} {tokens[-1]}\"\n",
        "        if _norm(alt) != name_key:\n",
        "            queries.append(alt)\n",
        "\n",
        "    errors, li, fb = [], [], []\n",
        "    calls = 0\n",
        "\n",
        "    for q in queries:\n",
        "        li_rows, li_err = await _call_tool(search_linkedin_people, {\"q\": q, \"limit\": MAX_CANDIDATES_PER_SOURCE, \"fuzzy\": True}, \"li_search\")\n",
        "        fb_rows, fb_err = await _call_tool(search_facebook_users, {\"q\": q, \"limit\": MAX_CANDIDATES_PER_SOURCE, \"fuzzy\": True}, \"fb_search\")\n",
        "        calls += 2\n",
        "\n",
        "        if li_err: errors.append(li_err)\n",
        "        if fb_err: errors.append(fb_err)\n",
        "\n",
        "        for r in _safe_list(li_rows)[:MAX_CANDIDATES_PER_SOURCE]:\n",
        "            li.append({**r, \"source\": \"linkedin\", \"candidate_name\": _candidate_name(r)})\n",
        "        for r in _safe_list(fb_rows)[:MAX_CANDIDATES_PER_SOURCE]:\n",
        "            fb.append({**r, \"source\": \"facebook\", \"candidate_name\": _candidate_name(r)})\n",
        "\n",
        "        if li or fb: break\n",
        "\n",
        "    def _dedup(rows):\n",
        "        seen, out = set(), []\n",
        "        for r in _safe_list(rows):\n",
        "            if r.get(\"id\") not in seen:\n",
        "                seen.add(r.get(\"id\"))\n",
        "                out.append(r)\n",
        "        return out\n",
        "\n",
        "    li, fb = _dedup(li)[:MAX_CANDIDATES_PER_SOURCE], _dedup(fb)[:MAX_CANDIDATES_PER_SOURCE]\n",
        "\n",
        "    if name_key and (li or fb):\n",
        "        _NAME_SEARCH_CACHE[name_key] = {\"linkedin\": li, \"facebook\": fb}\n",
        "\n",
        "    return li, fb, errors[:8], calls\n",
        "\n",
        "# -------------------------\n",
        "# 2. ç”»åƒæŠ“å–ä¸Žå¯¹æ¯”é€»è¾‘ (Fetch & Analysis Layer)\n",
        "# -------------------------\n",
        "async def _fetch_one_profile(source: str, row: dict):\n",
        "    raw_id = row.get(\"id\")\n",
        "    if not raw_id: return None, \"invalid_id\", 0\n",
        "\n",
        "    cache_key = f\"{source}:{raw_id}\"\n",
        "    if cache_key in _PROFILE_CACHE:\n",
        "        return {\"source\": source, \"id\": raw_id, \"profile\": _PROFILE_CACHE[cache_key]}, None, 0\n",
        "\n",
        "    tool = get_linkedin_profile if source == \"linkedin\" else get_facebook_profile\n",
        "    payload = {\"person_id\" if source == \"linkedin\" else \"user_id\": raw_id}\n",
        "\n",
        "    data, err = await _call_tool(tool, payload, f\"{source}_profile\")\n",
        "    if not err and isinstance(data, dict):\n",
        "        _PROFILE_CACHE[cache_key] = data\n",
        "        return {\"source\": source, \"id\": raw_id, \"profile\": data, \"candidate_name\": _candidate_name(row)}, None, 1\n",
        "    return None, err, 1\n",
        "\n",
        "async def _fetch_profiles(li_candidates: list, fb_candidates: list):\n",
        "    tasks = []\n",
        "    for r in _safe_list(li_candidates)[:MAX_PROFILES_PER_SOURCE]: tasks.append(_fetch_one_profile(\"linkedin\", r))\n",
        "    for r in _safe_list(fb_candidates)[:MAX_PROFILES_PER_SOURCE]: tasks.append(_fetch_one_profile(\"facebook\", r))\n",
        "\n",
        "    if not tasks: return [], [], 0\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    profiles, errors, calls = [], [], 0\n",
        "    for res in results:\n",
        "        if isinstance(res, Exception): errors.append(str(res))\n",
        "        elif res[0]:\n",
        "            profiles.append(res[0])\n",
        "            calls += res[2]\n",
        "        elif res[1]: errors.append(res[1])\n",
        "    return profiles, errors[:8], calls\n",
        "\n",
        "# -------------------------\n",
        "# 3. LLM è£åˆ¤é€»è¾‘ (çº¯å‡€é€šç”¨ Prompt è®¾è®¡)\n",
        "# -------------------------\n",
        "async def _llm_judge(evidence_pack: dict):\n",
        "    prompt = (\n",
        "        \"You are an expert CV Authenticity Judge. Compare CV claims against fetched social profiles.\\n\"\n",
        "        \"Return ONLY a JSON object with keys: score, confidence, rationale, findings. score must be a float [0,1].\\n\"\n",
        "        \"\\nSCORING POLICY (Strictly follow these logical rules):\\n\"\n",
        "        \"1. BASELINE: Start from a neutral 0.50.\\n\"\n",
        "        \"2. STRONG MATCH (Score 0.80 - 1.00): If one profile strongly matches the non-trivial claims (e.g., University, Degree, and Experience start years). Ignore minor profile data glitches (like 'is_current: false') if the core facts align.\\n\"\n",
        "        \"3. SEARCH MISS vs. FRAUD (CRITICAL DISTINCTION):\\n\"\n",
        "        \"   - SEARCH MISS (Score 0.55 - 0.65): If the CV is sparse or uses a common name, and the fetched profiles clearly belong to DIFFERENT people (e.g., completely different universities/industries), do NOT penalize. This is a Search Miss. Innocent until proven guilty. Give a passing score.\\n\"\n",
        "        \"   - PROVEN FRAUD (Score 0.10 - 0.35): You must heavily penalize ONLY IF you find impossible chronological facts. This means either the CV itself claims future dates (e.g., 2027), OR the fetched profiles for this candidate contain future dates (e.g., ending in 2025+), indicating a fabricated/synthetic identity cluster.\\n\"\n",
        "        f\"\\nEVIDENCE: {json.dumps(evidence_pack, ensure_ascii=False)}\"\n",
        "    )\n",
        "\n",
        "    # ä¿ç•™ 3 æ¬¡é‡è¯•å’Œæš´åŠ›æå– JSON çš„é˜²å´©æºƒæœºåˆ¶\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            resp = await asyncio.wait_for(llm.ainvoke([HumanMessage(content=prompt)]), timeout=30.0)\n",
        "            content = resp.content if isinstance(resp.content, str) else str(resp.content)\n",
        "\n",
        "            start_idx = content.find('{')\n",
        "            end_idx = content.rfind('}')\n",
        "            if start_idx == -1 or end_idx == -1:\n",
        "                raise ValueError(\"LLM æœªè¿”å›ž JSON\")\n",
        "\n",
        "            clean_json = content[start_idx:end_idx+1]\n",
        "            data = json.loads(clean_json)\n",
        "\n",
        "            return {\n",
        "                \"ok\": True,\n",
        "                \"score\": round(float(data.get(\"score\", 0.5)), 3),\n",
        "                \"confidence\": data.get(\"confidence\", \"medium\"),\n",
        "                \"rationale\": data.get(\"rationale\", \"No rationale provided\"),\n",
        "                \"findings\": _safe_list(data.get(\"findings\", []))[:6]\n",
        "            }\n",
        "        except Exception as e:\n",
        "            if attempt < 2:\n",
        "                print(f\"    âš ï¸ LLM æŽ¥å£ç¹å¿™ï¼Œæ­£åœ¨è¿›è¡Œç¬¬ {attempt+2} æ¬¡å°è¯•...\")\n",
        "                await asyncio.sleep(3)\n",
        "            else:\n",
        "                return {\"ok\": False, \"score\": 0.5, \"confidence\": \"low\", \"rationale\": f\"API Error: {str(e)}\", \"findings\": [\"LLM processing failed.\"]}\n",
        "# -------------------------\n",
        "# 4. æ ¸å¿ƒå·¥ä½œæµå…¥å£\n",
        "# -------------------------\n",
        "async def verify_cv(cv_path: str):\n",
        "    cv_id = Path(cv_path).name\n",
        "    _log_event(\"cv.start\", cv_id=cv_id)\n",
        "\n",
        "    text = extract_text_pdf(cv_path)\n",
        "    cv_claim = parse_cv(text)\n",
        "\n",
        "    async with _get_name_lock(cv_claim.get(\"name\")):\n",
        "        li_cands, fb_cands, s_errs, s_calls = await _search_candidates(cv_claim.get(\"name\"))\n",
        "        profiles, p_errs, p_calls = await _fetch_profiles(li_cands, fb_cands)\n",
        "\n",
        "    all_errs = (s_errs + p_errs)[:10]\n",
        "    hard_findings = _build_hard_findings(cv_claim, profiles, all_errs)\n",
        "    hard_fail, hard_score, hard_reason = _hard_fail_decision(cv_claim, profiles, hard_findings)\n",
        "\n",
        "    if not hard_fail:\n",
        "        evidence = _build_evidence_pack(cv_id, cv_claim, profiles, hard_findings, all_errs)\n",
        "        judge = await _llm_judge(evidence)\n",
        "        score, decision = judge[\"score\"], (\"pass\" if judge[\"score\"] >= PASS_THRESHOLD else \"fail\")\n",
        "        res_llm = judge\n",
        "    else:\n",
        "        score, decision = hard_score, \"fail\"\n",
        "        res_llm = {\"ok\": True, \"confidence\": \"high\", \"rationale\": hard_reason, \"score_raw\": hard_score, \"findings\": []}\n",
        "\n",
        "    report = _build_report(cv_id, cv_claim, score, decision, res_llm[\"confidence\"], res_llm[\"rationale\"], hard_findings + res_llm.get(\"findings\", []), score, len(profiles), s_calls + p_calls, all_errs)\n",
        "    _log_event(\"cv.complete\", cv_id=cv_id, decision=decision, score=score)\n",
        "\n",
        "    return {\"cv_id\": cv_id, \"score\": score, \"decision\": decision, \"verification_report\": {\"report_text\": report}}\n",
        "\n",
        "# -------------------------\n",
        "# 5. æ‰¹å¤„ç†é©±åŠ¨å‡½æ•°\n",
        "# -------------------------\n",
        "async def run_cv_verification(cv_files: list[str], max_concurrency=MAX_CV_VERIFY_CONCURRENCY):\n",
        "    sem = asyncio.Semaphore(max_concurrency)\n",
        "    async def _safe_run(f):\n",
        "        async with sem:\n",
        "            try: return await verify_cv(f)\n",
        "            except Exception as e: return {\"cv_id\": Path(f).name, \"score\": 0.0, \"decision\": \"fail\", \"error\": str(e)}\n",
        "\n",
        "    results = await asyncio.gather(*[_safe_run(f) for f in cv_files])\n",
        "    return {\"scores\": [r[\"score\"] for r in results], \"results\": results}"
      ],
      "metadata": {
        "id": "y_TRI89HT3AQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# æ–‡æœ¬è¾…åŠ©å¤„ç†å‡½æ•° (æå–å…³é”®å­—æ®µ)\n",
        "# -------------------------\n",
        "def _list_to_text(rows):\n",
        "    out = []\n",
        "    for r in _safe_list(rows):\n",
        "        if isinstance(r, dict):\n",
        "            out.append(str(r.get(\"raw\") or r))\n",
        "        else:\n",
        "            out.append(str(r))\n",
        "    return \" \".join(out)\n",
        "\n",
        "def _profile_to_text(profile: dict, key: str):\n",
        "    items = _safe_list((profile or {}).get(key, []))\n",
        "    parts = []\n",
        "    for item in items:\n",
        "        if isinstance(item, dict):\n",
        "            parts.append(\" \".join(str(v) for v in item.values() if v is not None))\n",
        "        else:\n",
        "            parts.append(str(item))\n",
        "    return \" \".join(parts)\n",
        "\n",
        "def _skills_to_text(profile: dict):\n",
        "    skills = _safe_list((profile or {}).get(\"skills\", []))\n",
        "    names = []\n",
        "    for s in skills:\n",
        "        if isinstance(s, dict):\n",
        "            names.append(str(s.get(\"name\") or \"\"))\n",
        "        else:\n",
        "            names.append(str(s))\n",
        "    return \" \".join(names)\n",
        "\n",
        "# -------------------------\n",
        "# æ ¸å¿ƒå‡½æ•°ï¼šè®¡ç®—ç®€åŽ†ä¸Žç”»åƒçš„ä¿¡æ¯é‡å åº¦\n",
        "# -------------------------\n",
        "def _profile_claim_overlap(cv_claim: dict, profile_row: dict):\n",
        "    profile = profile_row.get(\"profile\", {}) if isinstance(profile_row, dict) else {}\n",
        "\n",
        "    # å°†ä¸¤è¾¹çš„æ•°æ®è½¬æ¢ä¸ºé•¿æ–‡æœ¬\n",
        "    cv_exp = _list_to_text(cv_claim.get(\"experience\", []))\n",
        "    cv_edu = _list_to_text(cv_claim.get(\"education\", []))\n",
        "    cv_sk = \" \".join(_safe_list(cv_claim.get(\"skills\", [])))\n",
        "\n",
        "    pf_exp = _profile_to_text(profile, \"experience\")\n",
        "    pf_edu = _profile_to_text(profile, \"education\")\n",
        "    pf_sk = _skills_to_text(profile)\n",
        "\n",
        "    # æå–åˆ†è¯å¹¶æ±‚äº¤é›† (è®¡ç®—é‡å è¯æ±‡)\n",
        "    cv_exp_terms = set(_tokenize(cv_exp))\n",
        "    cv_edu_terms = set(_tokenize(cv_edu))\n",
        "    cv_sk_terms = set(_tokenize(cv_sk))\n",
        "\n",
        "    pf_exp_terms = set(_tokenize(pf_exp))\n",
        "    pf_edu_terms = set(_tokenize(pf_edu))\n",
        "    pf_sk_terms = set(_tokenize(pf_sk))\n",
        "\n",
        "    overlap_exp = sorted(list(cv_exp_terms & pf_exp_terms))[:12]\n",
        "    overlap_edu = sorted(list(cv_edu_terms & pf_edu_terms))[:12]\n",
        "    overlap_sk = sorted(list(cv_sk_terms & pf_sk_terms))[:12]\n",
        "\n",
        "    # è®¡ç®—å§“åç›¸ä¼¼åº¦\n",
        "    cv_name = cv_claim.get(\"name\") or \"\"\n",
        "    p_name = _candidate_name(profile)\n",
        "    name_similarity = round(_sim(cv_name, p_name), 3)\n",
        "\n",
        "    # æ•æ‰æ½œåœ¨çš„çŸ›ç›¾ä¿¡å·\n",
        "    mismatch_signals = []\n",
        "    if name_similarity < 0.60:\n",
        "        mismatch_signals.append(\"name similarity is low\")\n",
        "    if len(overlap_edu) == 0 and cv_edu_terms:\n",
        "        mismatch_signals.append(\"no education term overlap\")\n",
        "    if len(overlap_exp) == 0 and cv_exp_terms:\n",
        "        mismatch_signals.append(\"no experience term overlap\")\n",
        "\n",
        "    return {\n",
        "        \"source\": profile_row.get(\"source\"),\n",
        "        \"profile_id\": profile_row.get(\"id\"),\n",
        "        \"candidate_name\": profile_row.get(\"candidate_name\"),\n",
        "        \"profile_name\": p_name,\n",
        "        \"name_similarity\": name_similarity,\n",
        "        \"education_overlap_terms\": overlap_edu,\n",
        "        \"experience_overlap_terms\": overlap_exp,\n",
        "        \"skills_overlap_terms\": overlap_sk,\n",
        "        \"mismatch_signals\": mismatch_signals,\n",
        "        \"profile_compact\": _compact_profile(profile), # ä¾èµ–ä¹‹å‰çš„ _compact_profile\n",
        "    }"
      ],
      "metadata": {
        "id": "8rsSq3DwWxWR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####verification"
      ],
      "metadata": {
        "id": "rKS_bnCYUCrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  æ‰§è¡Œ CV éªŒè¯å¹¶æå–åˆ†æ•° (ç”¨äºŽæœ€ç»ˆè¯„ä¼°)\n",
        "# =====================================================\n",
        "\n",
        "# æ£€æŸ¥æ ¸å¿ƒéªŒè¯å‡½æ•°æ˜¯å¦å·²åŠ è½½ï¼Œé˜²æ­¢å› å•å…ƒæ ¼æœªè¿è¡Œå¯¼è‡´çš„æŠ¥é”™\n",
        "if \"run_cv_verification\" not in globals():\n",
        "    raise RuntimeError(\"æœªæ£€æµ‹åˆ° run_cv_verification å‡½æ•°ã€‚è¯·å…ˆè¿è¡Œä¹‹å‰çš„ç³»ç»Ÿæ ¸å¿ƒä»£ç å—ã€‚\")\n",
        "\n",
        "# å¯åŠ¨å¼‚æ­¥éªŒè¯æµç¨‹\n",
        "# ç³»ç»Ÿå°†æ ¹æ®ä¹‹å‰è®¾ç½®çš„å¹¶å‘æ•°ï¼ˆMAX_CV_VERIFY_CONCURRENCYï¼‰è‡ªåŠ¨å¤„ç† 5 ä»½ç®€åŽ†\n",
        "verification_result = await run_cv_verification(\n",
        "    cv_files,\n",
        "    max_concurrency=MAX_CV_VERIFY_CONCURRENCY,\n",
        ")\n",
        "\n",
        "# éåŽ†å¹¶æ‰“å°æ¯ä»½ç®€åŽ†çš„è¯¦ç»†éªŒè¯æŠ¥å‘Š\n",
        "# æŠ¥å‘ŠåŒ…å«ï¼šå†³ç­–å»ºè®®ã€å¾—åˆ†ã€LLM åˆ¤å®šç†ç”±ä»¥åŠå…·ä½“çš„å¼‚å¸¸å‘çŽ°ï¼ˆFindingsï¼‰\n",
        "for result_item in verification_result.get(\"results\", []):\n",
        "    report = result_item.get(\"verification_report\", {})\n",
        "    text = report.get(\"report_text\", \"\")\n",
        "    if text:\n",
        "        print(\"=\" * 88)\n",
        "        print(text)\n",
        "        print(\"\\n\")\n",
        "\n",
        "# æå–ç”¨äºŽä½œä¸šè¯„åˆ†çš„åŽŸå§‹åˆ†æ•°åˆ—è¡¨\n",
        "# scores æ ¼å¼åº”ä¸º [s1, s2, s3, s4, s5]ï¼Œå…¶ä¸­æ¯ä¸ª s ä¸º 0.0 åˆ° 1.0 ä¹‹é—´çš„æµ®ç‚¹æ•°\n",
        "scores = verification_result[\"scores\"]\n",
        "\n",
        "# æ‰“å°æœ€ç»ˆå¾—åˆ†æ•°ç»„ï¼Œè¿™ä¸€æ­¥çš„ç»“æžœå°†ç›´æŽ¥å¯¹æŽ¥ Evaluation å•å…ƒæ ¼\n",
        "print(\"Final Scores for Evaluation:\")\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nul7XTfUBfQ",
        "outputId": "5b7a76b7-0b80-4199-c208-38903df9560a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"event\": \"cv.start\", \"cv_id\": \"CV_1.pdf\"}\n",
            "{\"event\": \"cv.complete\", \"cv_id\": \"CV_1.pdf\", \"decision\": \"pass\", \"score\": 0.95}\n",
            "{\"event\": \"cv.start\", \"cv_id\": \"CV_2.pdf\"}\n",
            "{\"event\": \"cv.complete\", \"cv_id\": \"CV_2.pdf\", \"decision\": \"pass\", \"score\": 0.95}\n",
            "{\"event\": \"cv.start\", \"cv_id\": \"CV_3.pdf\"}\n",
            "{\"event\": \"cv.complete\", \"cv_id\": \"CV_3.pdf\", \"decision\": \"pass\", \"score\": 0.6}\n",
            "{\"event\": \"cv.start\", \"cv_id\": \"CV_4.pdf\"}\n",
            "{\"event\": \"cv.complete\", \"cv_id\": \"CV_4.pdf\", \"decision\": \"fail\", \"score\": 0.2}\n",
            "{\"event\": \"cv.start\", \"cv_id\": \"CV_5.pdf\"}\n",
            "{\"event\": \"cv.complete\", \"cv_id\": \"CV_5.pdf\", \"decision\": \"fail\", \"score\": 0.15}\n",
            "========================================================================================\n",
            "CV Verification Report | CV_1.pdf\n",
            "------------------------------------------------------------------------\n",
            "Summary\n",
            "  Decision : PASS\n",
            "  Score    : 0.950 (threshold=0.50)\n",
            "  Name     : John Smith\n",
            "\n",
            "Model Signals\n",
            "  LLM confidence : 0.9\n",
            "  LLM score raw  : 0.950\n",
            "\n",
            "Search Evidence\n",
            "  Profiles fetched : 4\n",
            "  MCP tool calls   : 2\n",
            "\n",
            "Rationale\n",
            "  LinkedIn profile ID 9 provides a strong and consistent match with the CV's key claims.\n",
            "  The education details (McGill University, BSc in Marketing, 2005-2009) perfectly align\n",
            "  with the CV's stated university, degree, and the implied graduation year (2009). The\n",
            "  experience start year (2020) also directly matches the CV's '2020 â€“ Present' claim.\n",
            "  The 'is_current: false' flag for the experience in the profile is considered a minor\n",
            "  data glitch as per the scoring policy and does not detract from the strong match.\n",
            "  Other profiles (LinkedIn ID 8, Facebook ID 8, Facebook ID 51) clearly belong to\n",
            "  different individuals with the same common name, indicating a 'Search Miss' for those\n",
            "  specific profiles, but not a lack of authenticity for the candidate's CV.\n",
            "\n",
            "Findings\n",
            "  - {'type': 'STRONG_MATCH', 'profile_id': 9, 'source': 'linkedin', 'matched_claims': ['Education: McGill University, Bachelor of Science (BSc) in Marketing (profile: McGill University, BSc, Marketing, 2005-2009)', 'Experience: Start year 2020 (profile: ByteDance, start_year 2020)'], 'details': 'LinkedIn profile ID 9 strongly corroborates both the education and experience start year claims from the CV. The university, degree, field, and start/end years for education are a direct match. The experience start year also aligns perfectly.'}\n",
            "  - {'type': 'SEARCH_MISS', 'profile_id': 8, 'source': 'linkedin', 'details': 'LinkedIn profile ID 8 belongs to a different individual named John Smith, with different education (University of Sydney, PhD in Finance) and experience (Hang Seng Bank, starting 2008). This is a search miss, not a CV mismatch.'}\n",
            "  - {'type': 'SEARCH_MISS', 'profile_id': 8, 'source': 'facebook', 'details': \"Facebook profile ID 8 is sparse but matches the location of LinkedIn ID 8, suggesting it's the same different individual. It does not match the CV.\"}\n",
            "  - {'type': 'SEARCH_MISS', 'profile_id': 51, 'source': 'facebook', 'details': 'Facebook profile ID 51 is sparse and does not contain information matching the CV. It appears to be another different individual with the same name.'}\n",
            "  - {'type': 'NO_FRAUD_DETECTED', 'details': 'No impossible chronological facts (e.g., future dates) were found in the CV or any of the fetched profiles.'}\n",
            "\n",
            "\n",
            "========================================================================================\n",
            "CV Verification Report | CV_2.pdf\n",
            "------------------------------------------------------------------------\n",
            "Summary\n",
            "  Decision : PASS\n",
            "  Score    : 0.950 (threshold=0.50)\n",
            "  Name     : Minh Pham\n",
            "\n",
            "Model Signals\n",
            "  LLM confidence : High\n",
            "  LLM score raw  : 0.950\n",
            "\n",
            "Search Evidence\n",
            "  Profiles fetched : 4\n",
            "  MCP tool calls   : 2\n",
            "\n",
            "Rationale\n",
            "  The candidate's CV claims for education (BSc in Design from The University of Hong\n",
            "  Kong) and experience dates (2022-Present, 2013-2017) are strongly corroborated by\n",
            "  LinkedIn profile 47. This profile also aligns with the CV's ambiguous '2011' claim,\n",
            "  which matches the education end year. The associated Facebook profile 70 shares the\n",
            "  same location, reinforcing the match. Other fetched profiles (ID 62) clearly belong to\n",
            "  a different individual with the same common name, representing a search miss rather\n",
            "  than a discrepancy for the candidate.\n",
            "\n",
            "Findings\n",
            "  - ['profile_comparisons[0].profile_compact.education', 'profile_comparisons[0].profile_compact.experience', 'cv_claim.education', 'cv_claim.experience']\n",
            "  - ['profile_comparisons[3].profile_compact.name', 'profile_comparisons[3].profile_compact.location', 'profile_comparisons[0].profile_compact.name', 'profile_comparisons[0].profile_compact.location']\n",
            "  - ['profile_comparisons[1].profile_compact.education', 'profile_comparisons[2].profile_compact.location', 'cv_claim.education']\n",
            "  - ['cv_claim', 'profile_comparisons[0].profile_compact']\n",
            "\n",
            "\n",
            "========================================================================================\n",
            "CV Verification Report | CV_3.pdf\n",
            "------------------------------------------------------------------------\n",
            "Summary\n",
            "  Decision : PASS\n",
            "  Score    : 0.600 (threshold=0.50)\n",
            "  Name     : Wei Zhang\n",
            "\n",
            "Model Signals\n",
            "  LLM confidence : 0.7\n",
            "  LLM score raw  : 0.600\n",
            "\n",
            "Search Evidence\n",
            "  Profiles fetched : 4\n",
            "  MCP tool calls   : 2\n",
            "\n",
            "Rationale\n",
            "  The CV provides a common name ('Wei Zhang') and sparse details for education\n",
            "  ('University of Tokyo', 'BSc in Consulting') and experience (only years '2013 â€“\n",
            "  Present', '2015'). While multiple social profiles for 'Wei Zhang' were found, none of\n",
            "  them align with the specific educational institution or degree claimed in the CV. The\n",
            "  profiles found clearly belong to different individuals, showing distinct universities\n",
            "  (e.g., KAIST, NTU) and professional backgrounds across various global locations\n",
            "  (Sydney, Hyderabad, San Francisco, Munich). This scenario is a clear 'Search Miss' due\n",
            "  to the common name and lack of specific matching data, rather than an indication of\n",
            "  fraud. No impossible chronological facts or future dates were detected in either the\n",
            "  CV or the fetched profiles.\n",
            "\n",
            "Findings\n",
            "  - CV claims: Name 'Wei Zhang', Education 'BSc in Consulting' from 'University of Tokyo', Experience years '2013 â€“ Present' and '2015'.\n",
            "  - Profile 24 (LinkedIn): 'Wei Zhang' with education at 'KAIST' (MBA, Legal) and experience at 'Shopee', 'Traveloka', 'TechWorks'. No overlap with CV claims.\n",
            "  - Profile 37 (LinkedIn): 'Wei Zhang' with education at 'NTU' (MSc, Education) and experience at 'AIA'. No overlap with CV claims.\n",
            "  - Profiles 76 & 97 (Facebook): 'Wei Zhang' with no education or experience details provided.\n",
            "  - No strong matches were found between the CV's specific education institution or degree and any of the fetched social profiles.\n",
            "  - The fetched profiles represent distinct individuals with different educational and professional backgrounds, indicating a search miss rather than a match to the CV candidate.\n",
            "\n",
            "\n",
            "========================================================================================\n",
            "CV Verification Report | CV_4.pdf\n",
            "------------------------------------------------------------------------\n",
            "Summary\n",
            "  Decision : FAIL\n",
            "  Score    : 0.200 (threshold=0.50)\n",
            "  Name     : Rahul Sharma\n",
            "\n",
            "Model Signals\n",
            "  LLM confidence : high\n",
            "  LLM score raw  : 0.200\n",
            "\n",
            "Search Evidence\n",
            "  Profiles fetched : 4\n",
            "  MCP tool calls   : 2\n",
            "\n",
            "Rationale\n",
            "  Implausible future-dated CV timeline\n",
            "\n",
            "Findings\n",
            "  - CV includes far-future years: [2027]\n",
            "\n",
            "\n",
            "========================================================================================\n",
            "CV Verification Report | CV_5.pdf\n",
            "------------------------------------------------------------------------\n",
            "Summary\n",
            "  Decision : FAIL\n",
            "  Score    : 0.150 (threshold=0.50)\n",
            "  Name     : Rahul Sharma\n",
            "\n",
            "Model Signals\n",
            "  LLM confidence : 0.9\n",
            "  LLM score raw  : 0.150\n",
            "\n",
            "Search Evidence\n",
            "  Profiles fetched : 4\n",
            "  MCP tool calls   : 2\n",
            "\n",
            "Rationale\n",
            "  The CV claims a PhD in Artificial Intelligence from the University of Tokyo and\n",
            "  specific experience dates. None of the fetched social profiles (LinkedIn or Facebook)\n",
            "  show any alignment with these core educational or professional claims. Furthermore,\n",
            "  two distinct LinkedIn profiles (ID 4 and ID 7), both named 'Rahul Sharma', contain\n",
            "  experience entries with end dates in the future (2025). This is a critical indicator\n",
            "  of fabricated or synthetic profiles, triggering a heavy penalty for proven fraud as\n",
            "  per the scoring policy. The lack of any matching information combined with the\n",
            "  presence of impossible chronological facts in the fetched profiles strongly suggests\n",
            "  that the CV claims are not verifiable and the associated profiles are fraudulent.\n",
            "\n",
            "Findings\n",
            "  - No education claims (PhD in Artificial Intelligence, University of Tokyo) from the CV could be verified across any of the fetched profiles.\n",
            "  - No experience claims (e.g., 2019-2021, 2016-Present) from the CV could be verified across any of the fetched profiles.\n",
            "  - LinkedIn profile ID 4 (Rahul Sharma) lists an experience at 'Hang Seng Bank' ending in 2025, which is a future date, indicating a fabricated entry.\n",
            "  - LinkedIn profile ID 7 (Rahul Sharma) lists an experience at 'Traveloka' ending in 2025, which is a future date, indicating a fabricated entry.\n",
            "  - The fetched profiles appear to belong to different individuals, none of whom match the CV's specific details, and two of them exhibit fraudulent date patterns.\n",
            "\n",
            "\n",
            "Final Scores for Evaluation:\n",
            "[0.95, 0.95, 0.6, 0.2, 0.15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation code\n",
        "\n",
        "In the test phase, you will be given 5 CV files with fixed names:\n",
        "\n",
        "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
        "\n",
        "Your system must process these CVs and output a list of 5 scores,\n",
        "one score per CV, in the same order:\n",
        "\n",
        "    scores = [s1, s2, s3, s4, s5]\n",
        "\n",
        "Each score must be a float in the range [0, 1], representing the\n",
        "reliability or confidence that the CV is valid (or meets the task criteria).\n",
        "\n",
        "The ground-truth labels are binary:\n",
        "\n",
        "    groundtruth = [0 or 1, ..., 0 or 1]\n",
        "\n",
        "Each CV is evaluated independently using a threshold of 0.5:\n",
        "\n",
        "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
        "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
        "- Otherwise â†’ No credit\n",
        "\n",
        "In other words, 0.5 is the decision threshold.\n",
        "\n",
        "- Each CV contributes equally.\n",
        "- Final score = (number of correct decisions) / 5\n"
      ],
      "metadata": {
        "id": "UqO99iOlq6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Evaluation code\n",
        "# =====================================================\n",
        "\n",
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "    \"\"\"\n",
        "    scores: list of floats in [0, 1], length = 5\n",
        "    groundtruth: list of ints (0 or 1), length = 5\n",
        "    \"\"\"\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0TtL07airIqz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groundtruth = [1, 1, 1, 0, 0] # Do not modify\n",
        "\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9TJ3N0CZrGY",
        "outputId": "ad74956a-32b5-4abf-d528-b4eeacd52f5b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'decisions': [1, 1, 1, 0, 0], 'correct': 5, 'total': 5, 'final_score': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l2kWbl4ZaGkM"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}